{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975762d8-59c0-487f-b58d-4b290dd29808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684c3d3c-eece-401a-9039-e0dfde09f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and get API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GRIDSTATUS_API_KEY\")\n",
    "assert api_key is not None, \"GRIDSTATUS_API_KEY not found in environment!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507410a8-2180-49a2-b10d-3034927f2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemre\\AppData\\Local\\Temp\\ipykernel_16816\\268586111.py:24: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  pd.to_datetime(df[\"interval_start_local\"])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(StringIO(resp\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# timezone workaround to avoid error of timezones not matching\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 1. Parse as naive datetime, then assign Central Time (NO SHIFT)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterval_start_local\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     24\u001b[0m     pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterval_start_local\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m       \u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica/Chicago\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 2. Apply cutoff (convert both sides to same tz)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m cutoff_ct \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-12-31 23:59:59\u001b[39m\u001b[38;5;124m\"\u001b[39m, tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica/Chicago\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Base URL\n",
    "url = \"https://api.gridstatus.io/v1/datasets/ercot_solar_actual_and_forecast_by_geo_region_hourly/query\"\n",
    "\n",
    "# Query parameters\n",
    "params = {\n",
    "    \"start_time\": \"2022-06-30\",\n",
    "    \"end_time\":   \"2024-12-31\",\n",
    "    \"publish_time\": \"latest\",\n",
    "    \"timezone\": \"market\",\n",
    "    \"api_key\": api_key,\n",
    "    \"return_format\": \"csv\",\n",
    "}\n",
    "\n",
    "# Make request\n",
    "resp = requests.get(url, params=params)\n",
    "resp.raise_for_status()\n",
    "\n",
    "df = pd.read_csv(StringIO(resp.text))\n",
    "\n",
    "# timezone workaround to avoid error of timezones not matching\n",
    "\n",
    "# 1. Parse timestamps as UTC (prevents mixed offset errors)\n",
    "df[\"interval_start_local\"] = pd.to_datetime(df[\"interval_start_local\"], utc=True)\n",
    "\n",
    "# 2. Apply cutoff (also tz-aware)\n",
    "cutoff_utc = pd.Timestamp(\"2024-12-31 23:59:59\", tz=\"UTC\")\n",
    "df = df[df[\"interval_start_local\"] <= cutoff_utc].copy()\n",
    "\n",
    "# 3. Convert UTC â†’ ERCOT local time\n",
    "df[\"interval_start_local\"] = df[\"interval_start_local\"].dt.tz_convert(\"America/Chicago\")\n",
    "\n",
    "# include systemwide + all regions\n",
    "\n",
    "regions = [\"system_wide\", \"centerwest\", \"northwest\", \"fareast\", \"southeast\", \"centereast\"]\n",
    "\n",
    "solar_cols = [\"interval_start_local\"]\n",
    "\n",
    "for r in regions:\n",
    "    solar_cols += [\n",
    "        f\"pvgrpp_{r}\",\n",
    "        f\"stppf_{r}\",\n",
    "        f\"cop_hsl_{r}\",\n",
    "        f\"gen_{r}\",\n",
    "    ]\n",
    "\n",
    "# Some systemwide datasets include an extra \"hsl_system_wide\"\n",
    "if \"hsl_system_wide\" in df.columns:\n",
    "    solar_cols.append(\"hsl_system_wide\")\n",
    "\n",
    "df_solar_all = (\n",
    "    df[solar_cols]\n",
    "    .sort_values(\"interval_start_local\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df_solar_all.shape)\n",
    "df_solar_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44c3a2-15c8-4a16-a136-62a5b4d45523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv to folder\n",
    "df_solar_all.to_csv(\n",
    "    r\"C:\\Users\\lemre\\Documents\\ERCOT_Peaker_Project\\ercot_solar_allzones_2022_2024.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9cad8-00de-4bca-a535-bcb391ea8a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
