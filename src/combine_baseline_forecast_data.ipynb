{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed09d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "hourly_load = pd.read_csv('../clean_data/forecasts/ercot_load_forecast_2025-01-01_to_2025-09_01_combined_latest.csv', parse_dates=['interval_start_local'])\n",
    "solar = pd.read_csv('../clean_data/ercot_solar_forecasts_allzones_2025.csv', parse_dates=['interval_start_local'])\n",
    "wind = pd.read_csv('../clean_data/ercot_wind_forecasts_hourly_2025.csv', parse_dates=['interval_start_local'])\n",
    "lmp = pd.read_csv('../clean_data/LMP_2025_Hubs.csv', parse_dates=['datetime'])\n",
    "weather = pd.read_csv('../clean_data/weather_hourly_2025.csv', parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece7573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hourly_load -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2025-01-01 00:00:00\n",
       "1  2025-01-01 01:00:00\n",
       "2  2025-01-01 02:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2025-01-01 00:00:00\n",
       "1  2025-01-01 01:00:00\n",
       "2  2025-01-01 02:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2025-01-01 00:00:00\n",
       "1  2025-01-01 01:00:00\n",
       "2  2025-01-01 02:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmp -> datetime dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime\n",
       "0 2024-12-31 18:00:00\n",
       "1 2024-12-31 19:00:00\n",
       "2 2024-12-31 20:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather -> datetime dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime\n",
       "0 2024-12-31 18:00:00\n",
       "1 2024-12-31 19:00:00\n",
       "2 2024-12-31 20:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def ensure_localized(df, col, tz='America/Chicago', make_naive=True):\n",
    "    \"\"\"Parse `col` in `df` robustly and convert to timezone `tz`.\n",
    "    - Tries parsing with `utc=True` first (handles strings with offsets like `-06:00`).\n",
    "    - Falls back to parsing without `utc` and then localizing naive timestamps.\n",
    "    - Converts to `tz` and (optionally) drops tz info producing naive local times.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        print(f\"column not found: {col}\")\n",
    "        return\n",
    "    # First try: parse with utc=True (works for strings that include offsets)\n",
    "    s = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "    # If parsing produced all NaT or resulted in tz-naive series, try fallback parse\n",
    "    if s.isna().all() or (getattr(s.dt, 'tz', None) is None):\n",
    "        s = pd.to_datetime(df[col], errors='coerce')\n",
    "        # If still naive (no tz), localize to tz\n",
    "        if getattr(s.dt, 'tz', None) is None:\n",
    "            try:\n",
    "                s = s.dt.tz_localize(tz)\n",
    "            except Exception:\n",
    "                # some strings may already include offsets; reparse with utc\n",
    "                s = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "    # At this point s should be tz-aware (UTC or localized)\n",
    "    if getattr(s.dt, 'tz', None) is not None:\n",
    "        try:\n",
    "            s = s.dt.tz_convert(tz)\n",
    "        except Exception:\n",
    "            # if conversion fails, keep as-is\n",
    "            pass\n",
    "    # Optionally drop tz info to produce naive local timestamps\n",
    "    if make_naive and getattr(s.dt, 'tz', None) is not None:\n",
    "        s = s.dt.tz_localize(None)\n",
    "    df[col] = s\n",
    "\n",
    "# Apply to the dataframes already loaded above\n",
    "tz = 'America/Chicago'\n",
    "ensure_localized(hourly_load, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(solar, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(wind, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(lmp, 'datetime', tz=tz, make_naive=True)\n",
    "ensure_localized(weather, 'datetime', tz=tz, make_naive=True)\n",
    "\n",
    "# Quick verification prints\n",
    "for name, df, col in [\n",
    "    ('hourly_load', hourly_load, 'interval_start_local'),\n",
    "    ('solar', solar, 'interval_start_local'),\n",
    "    ('wind', wind, 'interval_start_local'),\n",
    "    ('lmp', lmp, 'datetime'),\n",
    "    ('weather', weather, 'datetime'),\n",
    "]:\n",
    "    if col in df.columns:\n",
    "        print(f\"{name} -> {col} dtype:\", df[col].dtype, \"nulls:\", df[col].isna().sum())\n",
    "        display(df[[col]].head(3))\n",
    "    else:\n",
    "        print(f\"{name} missing column {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62267a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind.drop(columns=['interval_start_utc', 'interval_end_utc', 'interval_end_local'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025c09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.rename(columns={'datetime':'interval_start_local'}, inplace=True)\n",
    "lmp.rename(columns={'datetime':'interval_start_local'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743daef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = hourly_load.merge(solar, on='interval_start_local', how='left')\n",
    "merged = merged.merge(wind, on='interval_start_local', how='left')\n",
    "merged = merged.merge(lmp, on='interval_start_local', how='left')\n",
    "merged = merged.merge(weather, on='interval_start_local', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a85a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_start_local      0\n",
       "interval_start_utc        0\n",
       "interval_end_local        0\n",
       "interval_end_utc          0\n",
       "publish_time_local_x      0\n",
       "                       ... \n",
       "SLP_qc                  146\n",
       "WIND_DIR_deg            407\n",
       "WIND_DIR_qc             146\n",
       "WIND_SPD_ms             148\n",
       "WIND_SPD_qc             146\n",
       "Length: 62, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da1dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[~merged['HB_BUSAVG'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86db07aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in merged (count=62):\n",
      "['interval_start_local', 'interval_start_utc', 'interval_end_local', 'interval_end_utc', 'publish_time_local_x', 'publish_time_utc_x', 'north', 'south', 'west', 'houston', 'system_total', 'forecast_date', 'publish_time_used', 'pvgrpp_system_wide', 'stppf_system_wide', 'cop_hsl_system_wide_x', 'pvgrpp_centerwest', 'stppf_centerwest', 'cop_hsl_centerwest', 'pvgrpp_northwest', 'stppf_northwest', 'cop_hsl_northwest', 'pvgrpp_fareast', 'stppf_fareast', 'cop_hsl_fareast', 'pvgrpp_southeast', 'stppf_southeast', 'cop_hsl_southeast', 'pvgrpp_centereast', 'stppf_centereast', 'cop_hsl_centereast', 'publish_time_local_y', 'publish_time_utc_y', 'cop_hsl_system_wide_y', 'stwpf_system_wide', 'wgrpp_system_wide', 'cop_hsl_lz_south_houston', 'stwpf_lz_south_houston', 'wgrpp_lz_south_houston', 'cop_hsl_lz_west', 'stwpf_lz_west', 'wgrpp_lz_west', 'cop_hsl_lz_north', 'stwpf_lz_north', 'wgrpp_lz_north', 'HB_BUSAVG', 'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST', 'TEMP_C', 'TEMP_qc', 'DEW_C', 'DEW_qc', 'SLP_hPa', 'SLP_qc', 'WIND_DIR_deg', 'WIND_DIR_qc', 'WIND_SPD_ms', 'WIND_SPD_qc']\n",
      "LMP/HB candidate columns: ['HB_BUSAVG', 'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST']\n",
      "Using column for LMP analysis: HB_BUSAVG\n",
      "count    5854.000000\n",
      "mean       31.887113\n",
      "std        44.532001\n",
      "min       -31.770000\n",
      "25%        19.482500\n",
      "50%        24.720000\n",
      "75%        34.750000\n",
      "max      1754.830000\n",
      "Name: HB_BUSAVG, dtype: float64\n",
      "nulls: 0 of 5854\n",
      "Sample non-null values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "      <th>HB_BUSAVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>20.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "      <td>20.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "      <td>21.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 03:00:00</td>\n",
       "      <td>14.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 04:00:00</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-01 05:00:00</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-01 06:00:00</td>\n",
       "      <td>15.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-01 07:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-01 08:00:00</td>\n",
       "      <td>14.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-01 09:00:00</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local  HB_BUSAVG\n",
       "0  2025-01-01 00:00:00      20.49\n",
       "1  2025-01-01 01:00:00      20.94\n",
       "2  2025-01-01 02:00:00      21.88\n",
       "3  2025-01-01 03:00:00      14.78\n",
       "4  2025-01-01 04:00:00       8.09\n",
       "5  2025-01-01 05:00:00      13.29\n",
       "6  2025-01-01 06:00:00      15.22\n",
       "7  2025-01-01 07:00:00      15.17\n",
       "8  2025-01-01 08:00:00      14.93\n",
       "9  2025-01-01 09:00:00       6.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with LMP present: 5854\n",
      "Gaps (diff>1.001h) among those rows: 2\n",
      "Days with full 24 hours for rows where LMP present: 242 of 244\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: inspect the in-memory `merged` DataFrame (cell 17 context)\n",
    "import pandas as pd\n",
    "# ensure datetime column is parsed if present\n",
    "dt_col = None\n",
    "for c in ['interval_start_local','datetime','start','timestamp']:\n",
    "    if c in merged.columns:\n",
    "        dt_col = c\n",
    "        break\n",
    "if dt_col is not None:\n",
    "    merged[dt_col] = pd.to_datetime(merged[dt_col], errors='coerce')\n",
    "print('Columns in merged (count={}):'.format(len(merged.columns)))\n",
    "print(list(merged.columns))\n",
    "# Find candidate HB/LMP columns by keyword\n",
    "candidates = [c for c in merged.columns if any(k in c.lower() for k in ('hb','busavg','lmp','hub','bus'))]\n",
    "print('LMP/HB candidate columns:', candidates)\n",
    "# If HB_BUSAVG exists, show its stats; otherwise show stats for candidates\n",
    "target = 'HB_BUSAVG' if 'HB_BUSAVG' in merged.columns else (candidates[0] if candidates else None)\n",
    "if target is None:\n",
    "    print('No HB/LMP-like column found in `merged`.')\n",
    "else:\n",
    "    print('Using column for LMP analysis:', target)\n",
    "    ser = merged[target]\n",
    "    print(ser.describe())\n",
    "    print('nulls:', ser.isna().sum(), 'of', len(ser))\n",
    "    # show sample values where not null\n",
    "    print('Sample non-null values:')\n",
    "    display(merged.loc[merged[target].notna(), [dt_col, target]].head(10))\n",
    "    # continuity check on rows where this LMP is present\n",
    "    if dt_col is not None:\n",
    "        df_present = merged.loc[merged[target].notna()].copy()\n",
    "        df_present = df_present.sort_values(dt_col)\n",
    "        s = pd.to_datetime(df_present[dt_col])\n",
    "        diffs = s.diff().dt.total_seconds()/3600.0\n",
    "        gaps = (diffs>1.001).sum()\n",
    "        print('Rows with LMP present:', len(df_present))\n",
    "        print('Gaps (diff>1.001h) among those rows:', gaps)\n",
    "        # per-day completeness\n",
    "        sdf = pd.DataFrame({dt_col: s})\n",
    "        sdf['date'] = sdf[dt_col].dt.date\n",
    "        sdf['hour'] = sdf[dt_col].dt.hour\n",
    "        days = []\n",
    "        for date, g in sdf.groupby('date'):\n",
    "            hours = sorted(g['hour'].unique())\n",
    "            days.append((date, len(hours)))\n",
    "        full_days = sum(1 for d,n in days if n==24)\n",
    "        print('Days with full 24 hours for rows where LMP present:', full_days, 'of', len(days))\n",
    "    else:\n",
    "        print('Skipping LMP continuity check because no datetime column found in merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a036eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../clean_data/test_data_forecast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58f545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
