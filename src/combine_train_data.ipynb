{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09afb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "hourly_load = pd.read_csv('../clean_data/hourly_load_act.csv', parse_dates=['interval_start_local'])\n",
    "solar = pd.read_csv('../clean_data/ercot_solar_actuals_allzones_2023_2024.csv', parse_dates=['interval_start_local'])\n",
    "wind = pd.read_csv('../clean_data/ercot_wind_actuals_hourly_2023_2024.csv', parse_dates=['interval_start_local'])\n",
    "lmp = pd.read_csv('../clean_data/LMP_2023_2024_Hubs.csv', parse_dates=['datetime'])\n",
    "weather = pd.read_csv('../clean_data/weather_hourly.csv', parse_dates=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4298fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_start_local    datetime64[ns]\n",
       "load                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_load.columns\n",
    "hourly_load.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d897f",
   "metadata": {},
   "source": [
    "## Normalize datetime columns\n",
    "\n",
    "Define a small helper to robustly parse and normalize datetime-like columns across datasets.\n",
    "This will convert timezone-offset strings to `America/Chicago` local time and produce naive datetimes for consistent merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d1d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column not found: datetime\n",
      "column not found: datetime\n",
      "hourly_load -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-31 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-31 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2020-12-31 18:00:00\n",
       "1  2020-12-31 19:00:00\n",
       "2  2020-12-31 20:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2023-01-01 00:00:00\n",
       "1  2023-01-01 01:00:00\n",
       "2  2023-01-01 02:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind -> interval_start_local dtype: datetime64[ns] nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interval_start_local\n",
       "0  2023-01-01 00:00:00\n",
       "1  2023-01-01 01:00:00\n",
       "2  2023-01-01 02:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmp missing column datetime\n",
      "weather missing column datetime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def ensure_localized(df, col, tz='America/Chicago', make_naive=True):\n",
    "    \"\"\"Parse `col` in `df` robustly and convert to timezone `tz`.\n",
    "    - Tries parsing with `utc=True` first (handles strings with offsets like `-06:00`).\n",
    "    - Falls back to parsing without `utc` and then localizing naive timestamps.\n",
    "    - Converts to `tz` and (optionally) drops tz info producing naive local times.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        print(f\"column not found: {col}\")\n",
    "        return\n",
    "    # First try: parse with utc=True (works for strings that include offsets)\n",
    "    s = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "    # If parsing produced all NaT or resulted in tz-naive series, try fallback parse\n",
    "    if s.isna().all() or (getattr(s.dt, 'tz', None) is None):\n",
    "        s = pd.to_datetime(df[col], errors='coerce')\n",
    "        # If still naive (no tz), localize to tz\n",
    "        if getattr(s.dt, 'tz', None) is None:\n",
    "            try:\n",
    "                s = s.dt.tz_localize(tz)\n",
    "            except Exception:\n",
    "                # some strings may already include offsets; reparse with utc\n",
    "                s = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "    # At this point s should be tz-aware (UTC or localized)\n",
    "    if getattr(s.dt, 'tz', None) is not None:\n",
    "        try:\n",
    "            s = s.dt.tz_convert(tz)\n",
    "        except Exception:\n",
    "            # if conversion fails, keep as-is\n",
    "            pass\n",
    "    # Optionally drop tz info to produce naive local timestamps\n",
    "    if make_naive and getattr(s.dt, 'tz', None) is not None:\n",
    "        s = s.dt.tz_localize(None)\n",
    "    df[col] = s\n",
    "\n",
    "# Apply to the dataframes already loaded above\n",
    "tz = 'America/Chicago'\n",
    "ensure_localized(hourly_load, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(solar, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(wind, 'interval_start_local', tz=tz, make_naive=True)\n",
    "ensure_localized(lmp, 'datetime', tz=tz, make_naive=True)\n",
    "ensure_localized(weather, 'datetime', tz=tz, make_naive=True)\n",
    "\n",
    "# Quick verification prints\n",
    "for name, df, col in [\n",
    "    ('hourly_load', hourly_load, 'interval_start_local'),\n",
    "    ('solar', solar, 'interval_start_local'),\n",
    "    ('wind', wind, 'interval_start_local'),\n",
    "    ('lmp', lmp, 'datetime'),\n",
    "    ('weather', weather, 'datetime'),\n",
    "]:\n",
    "    if col in df.columns:\n",
    "        print(f\"{name} -> {col} dtype:\", df[col].dtype, \"nulls:\", df[col].isna().sum())\n",
    "        display(df[[col]].head(3))\n",
    "    else:\n",
    "        print(f\"{name} missing column {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8de7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_start_local    datetime64[ns]\n",
       "gen_system_wide                float64\n",
       "gen_centerwest                 float64\n",
       "gen_northwest                  float64\n",
       "gen_fareast                    float64\n",
       "gen_southeast                  float64\n",
       "gen_centereast                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solar.columns\n",
    "solar.dtypes\n",
    "# Convert column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab119987",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['interval_start_utc', 'interval_end_utc', 'interval_end_local'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m wind.columns\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mwind\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minterval_start_utc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minterval_end_utc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minterval_end_local\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ERCOT_Peaker_Project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ERCOT_Peaker_Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ERCOT_Peaker_Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ERCOT_Peaker_Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['interval_start_utc', 'interval_end_utc', 'interval_end_local'] not found in axis\""
     ]
    }
   ],
   "source": [
    "wind.columns\n",
    "wind.drop(columns=['interval_start_utc', 'interval_end_utc', 'interval_end_local'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74466b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_start_local    datetime64[ns]\n",
       "HB_BUSAVG                      float64\n",
       "HB_HOUSTON                     float64\n",
       "HB_HUBAVG                      float64\n",
       "HB_NORTH                       float64\n",
       "HB_PAN                         float64\n",
       "HB_SOUTH                       float64\n",
       "HB_WEST                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmp.columns\n",
    "# Column types\n",
    "lmp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b48db2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['interval_start_local', 'TEMP_C', 'TEMP_qc', 'DEW_C', 'DEW_qc',\n",
       "       'SLP_hPa', 'SLP_qc', 'WIND_DIR_deg', 'WIND_DIR_qc', 'WIND_SPD_ms',\n",
       "       'WIND_SPD_qc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9004a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.rename(columns={'datetime':'interval_start_local'}, inplace=True)\n",
    "lmp.rename(columns={'datetime':'interval_start_local'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78eaea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = hourly_load.merge(solar, on='interval_start_local', how='left')\n",
    "merged = merged.merge(wind, on='interval_start_local', how='left')\n",
    "merged = merged.merge(lmp, on='interval_start_local', how='left')\n",
    "merged = merged.merge(weather, on='interval_start_local', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "398e34fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['interval_start_local', 'load', 'gen_system_wide_x', 'gen_centerwest',\n",
       "       'gen_northwest', 'gen_fareast', 'gen_southeast', 'gen_centereast',\n",
       "       'publish_time_utc', 'publish_time_local', 'gen_system_wide_y',\n",
       "       'gen_lz_south_houston', 'gen_lz_west', 'gen_lz_north', 'HB_BUSAVG',\n",
       "       'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST',\n",
       "       'TEMP_C', 'TEMP_qc', 'DEW_C', 'DEW_qc', 'SLP_hPa', 'SLP_qc',\n",
       "       'WIND_DIR_deg', 'WIND_DIR_qc', 'WIND_SPD_ms', 'WIND_SPD_qc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79cab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35040, 31)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfa6a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_start_local        0\n",
       "load                        7\n",
       "gen_system_wide_x       17527\n",
       "gen_centerwest          17527\n",
       "gen_northwest           17527\n",
       "gen_fareast             17527\n",
       "gen_southeast           17527\n",
       "gen_centereast          17527\n",
       "publish_time_utc        17526\n",
       "publish_time_local      17526\n",
       "gen_system_wide_y       17529\n",
       "gen_lz_south_houston    17529\n",
       "gen_lz_west             17529\n",
       "gen_lz_north            17529\n",
       "HB_BUSAVG               17526\n",
       "HB_HOUSTON              17526\n",
       "HB_HUBAVG               17526\n",
       "HB_NORTH                17526\n",
       "HB_PAN                  17526\n",
       "HB_SOUTH                17526\n",
       "HB_WEST                 17526\n",
       "TEMP_C                     13\n",
       "TEMP_qc                    20\n",
       "DEW_C                      16\n",
       "DEW_qc                     20\n",
       "SLP_hPa                    49\n",
       "SLP_qc                     11\n",
       "WIND_DIR_deg             1898\n",
       "WIND_DIR_qc                11\n",
       "WIND_SPD_ms                16\n",
       "WIND_SPD_qc                14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0b50066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with HB_BUSAVG is NA\n",
    "merged = merged[~merged['HB_BUSAVG'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b3f4a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17514, 31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check continuity\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d296a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['interval_start_local', 'load', 'gen_system_wide_x', 'gen_centerwest',\n",
       "       'gen_northwest', 'gen_fareast', 'gen_southeast', 'gen_centereast',\n",
       "       'publish_time_utc', 'publish_time_local', 'gen_system_wide_y',\n",
       "       'gen_lz_south_houston', 'gen_lz_west', 'gen_lz_north', 'HB_BUSAVG',\n",
       "       'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST',\n",
       "       'TEMP_C', 'TEMP_qc', 'DEW_C', 'DEW_qc', 'SLP_hPa', 'SLP_qc',\n",
       "       'WIND_DIR_deg', 'WIND_DIR_qc', 'WIND_SPD_ms', 'WIND_SPD_qc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0f7660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "      <th>load</th>\n",
       "      <th>gen_system_wide_x</th>\n",
       "      <th>gen_centerwest</th>\n",
       "      <th>gen_northwest</th>\n",
       "      <th>gen_fareast</th>\n",
       "      <th>gen_southeast</th>\n",
       "      <th>gen_centereast</th>\n",
       "      <th>publish_time_utc</th>\n",
       "      <th>publish_time_local</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TEMP_qc</th>\n",
       "      <th>DEW_C</th>\n",
       "      <th>DEW_qc</th>\n",
       "      <th>SLP_hPa</th>\n",
       "      <th>SLP_qc</th>\n",
       "      <th>WIND_DIR_deg</th>\n",
       "      <th>WIND_DIR_qc</th>\n",
       "      <th>WIND_SPD_ms</th>\n",
       "      <th>WIND_SPD_qc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17526</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>34969.250000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2023-01-03 06:55:33+00:00</td>\n",
       "      <td>2023-01-03T00:55:33-06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>17.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1007.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>35573.500000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2023-01-03 07:55:35+00:00</td>\n",
       "      <td>2023-01-03T01:55:35-06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>16.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1007.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17528</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>36279.750000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2023-01-03 08:55:33+00:00</td>\n",
       "      <td>2023-01-03T02:55:33-06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>16.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1008.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>36765.833333</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2023-01-03 09:55:29+00:00</td>\n",
       "      <td>2023-01-03T03:55:29-06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1008.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>37049.916667</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2023-01-03 10:55:19+00:00</td>\n",
       "      <td>2023-01-03T04:55:19-06:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1009.40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      interval_start_local          load  gen_system_wide_x  gen_centerwest  \\\n",
       "17526  2023-01-01 00:00:00  34969.250000               0.45            0.01   \n",
       "17527  2023-01-01 01:00:00  35573.500000               0.46            0.01   \n",
       "17528  2023-01-01 02:00:00  36279.750000               0.45            0.01   \n",
       "17529  2023-01-01 03:00:00  36765.833333               0.46            0.01   \n",
       "17530  2023-01-01 04:00:00  37049.916667               0.45            0.01   \n",
       "\n",
       "       gen_northwest  gen_fareast  gen_southeast  gen_centereast  \\\n",
       "17526            0.0         0.36            0.0            0.07   \n",
       "17527            0.0         0.37            0.0            0.07   \n",
       "17528            0.0         0.36            0.0            0.07   \n",
       "17529            0.0         0.37            0.0            0.07   \n",
       "17530            0.0         0.36            0.0            0.07   \n",
       "\n",
       "                publish_time_utc         publish_time_local  ...  TEMP_C  \\\n",
       "17526  2023-01-03 06:55:33+00:00  2023-01-03T00:55:33-06:00  ...   17.75   \n",
       "17527  2023-01-03 07:55:35+00:00  2023-01-03T01:55:35-06:00  ...   16.70   \n",
       "17528  2023-01-03 08:55:33+00:00  2023-01-03T02:55:33-06:00  ...   16.10   \n",
       "17529  2023-01-03 09:55:29+00:00  2023-01-03T03:55:29-06:00  ...   15.85   \n",
       "17530  2023-01-03 10:55:19+00:00  2023-01-03T04:55:19-06:00  ...   15.00   \n",
       "\n",
       "       TEMP_qc  DEW_C  DEW_qc  SLP_hPa  SLP_qc  WIND_DIR_deg  WIND_DIR_qc  \\\n",
       "17526      3.0    6.7     3.0  1007.75     3.0         185.0          3.0   \n",
       "17527      5.0    7.2     5.0  1007.90     5.0         180.0          5.0   \n",
       "17528      5.0    7.2     5.0  1008.70     5.0         170.0          5.0   \n",
       "17529      3.0    7.2     3.0  1008.80     3.0         175.0          3.0   \n",
       "17530      5.0    7.2     5.0  1009.40     5.0         190.0          5.0   \n",
       "\n",
       "       WIND_SPD_ms  WIND_SPD_qc  \n",
       "17526          4.1          3.0  \n",
       "17527          4.6          5.0  \n",
       "17528          3.1          5.0  \n",
       "17529          3.6          3.0  \n",
       "17530          4.6          5.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "322cf5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in merged (count=31):\n",
      "['interval_start_local', 'load', 'gen_system_wide_x', 'gen_centerwest', 'gen_northwest', 'gen_fareast', 'gen_southeast', 'gen_centereast', 'publish_time_utc', 'publish_time_local', 'gen_system_wide_y', 'gen_lz_south_houston', 'gen_lz_west', 'gen_lz_north', 'HB_BUSAVG', 'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST', 'TEMP_C', 'TEMP_qc', 'DEW_C', 'DEW_qc', 'SLP_hPa', 'SLP_qc', 'WIND_DIR_deg', 'WIND_DIR_qc', 'WIND_SPD_ms', 'WIND_SPD_qc']\n",
      "LMP/HB candidate columns: ['HB_BUSAVG', 'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_PAN', 'HB_SOUTH', 'HB_WEST']\n",
      "Using column for LMP analysis: HB_BUSAVG\n",
      "count    17514.000000\n",
      "mean        35.690520\n",
      "std        177.204636\n",
      "min        -31.770000\n",
      "25%         14.700000\n",
      "50%         20.340000\n",
      "75%         26.610000\n",
      "max       5054.490000\n",
      "Name: HB_BUSAVG, dtype: float64\n",
      "nulls: 0 of 17514\n",
      "Sample non-null values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_start_local</th>\n",
       "      <th>HB_BUSAVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17526</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>-2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>-1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17528</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>2023-01-01 05:00:00</td>\n",
       "      <td>-1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>2023-01-01 06:00:00</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>2023-01-01 07:00:00</td>\n",
       "      <td>11.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>2023-01-01 08:00:00</td>\n",
       "      <td>22.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17535</th>\n",
       "      <td>2023-01-01 09:00:00</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      interval_start_local  HB_BUSAVG\n",
       "17526  2023-01-01 00:00:00      -2.56\n",
       "17527  2023-01-01 01:00:00      -1.49\n",
       "17528  2023-01-01 02:00:00      -1.00\n",
       "17529  2023-01-01 03:00:00      -0.05\n",
       "17530  2023-01-01 04:00:00       0.00\n",
       "17531  2023-01-01 05:00:00      -1.55\n",
       "17532  2023-01-01 06:00:00       2.45\n",
       "17533  2023-01-01 07:00:00      11.93\n",
       "17534  2023-01-01 08:00:00      22.51\n",
       "17535  2023-01-01 09:00:00      10.88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with LMP present: 17514\n",
      "Gaps (diff>1.001h) among those rows: 2\n",
      "Days with full 24 hours for rows where LMP present: 727 of 730\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: inspect the in-memory `merged` DataFrame (cell 17 context)\n",
    "import pandas as pd\n",
    "# ensure datetime column is parsed if present\n",
    "dt_col = None\n",
    "for c in ['interval_start_local','datetime','start','timestamp']:\n",
    "    if c in merged.columns:\n",
    "        dt_col = c\n",
    "        break\n",
    "if dt_col is not None:\n",
    "    merged[dt_col] = pd.to_datetime(merged[dt_col], errors='coerce')\n",
    "print('Columns in merged (count={}):'.format(len(merged.columns)))\n",
    "print(list(merged.columns))\n",
    "# Find candidate HB/LMP columns by keyword\n",
    "candidates = [c for c in merged.columns if any(k in c.lower() for k in ('hb','busavg','lmp','hub','bus'))]\n",
    "print('LMP/HB candidate columns:', candidates)\n",
    "# If HB_BUSAVG exists, show its stats; otherwise show stats for candidates\n",
    "target = 'HB_BUSAVG' if 'HB_BUSAVG' in merged.columns else (candidates[0] if candidates else None)\n",
    "if target is None:\n",
    "    print('No HB/LMP-like column found in `merged`.')\n",
    "else:\n",
    "    print('Using column for LMP analysis:', target)\n",
    "    ser = merged[target]\n",
    "    print(ser.describe())\n",
    "    print('nulls:', ser.isna().sum(), 'of', len(ser))\n",
    "    # show sample values where not null\n",
    "    print('Sample non-null values:')\n",
    "    display(merged.loc[merged[target].notna(), [dt_col, target]].head(10))\n",
    "    # continuity check on rows where this LMP is present\n",
    "    if dt_col is not None:\n",
    "        df_present = merged.loc[merged[target].notna()].copy()\n",
    "        df_present = df_present.sort_values(dt_col)\n",
    "        s = pd.to_datetime(df_present[dt_col])\n",
    "        diffs = s.diff().dt.total_seconds()/3600.0\n",
    "        gaps = (diffs>1.001).sum()\n",
    "        print('Rows with LMP present:', len(df_present))\n",
    "        print('Gaps (diff>1.001h) among those rows:', gaps)\n",
    "        # per-day completeness\n",
    "        sdf = pd.DataFrame({dt_col: s})\n",
    "        sdf['date'] = sdf[dt_col].dt.date\n",
    "        sdf['hour'] = sdf[dt_col].dt.hour\n",
    "        days = []\n",
    "        for date, g in sdf.groupby('date'):\n",
    "            hours = sorted(g['hour'].unique())\n",
    "            days.append((date, len(hours)))\n",
    "        full_days = sum(1 for d,n in days if n==24)\n",
    "        print('Days with full 24 hours for rows where LMP present:', full_days, 'of', len(days))\n",
    "    else:\n",
    "        print('Skipping LMP continuity check because no datetime column found in merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e0ec18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../clean_data/train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c816f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
